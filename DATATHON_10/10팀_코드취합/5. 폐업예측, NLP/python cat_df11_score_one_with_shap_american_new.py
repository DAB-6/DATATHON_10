# -*- coding: utf-8 -*-
"""
cat_df11_score_one_with_shap.py
- cat_df11_close_real_bestF1.py ë¡œ í•™ìŠµí•œ ëª¨ë¸ì„ ì´ìš©í•´
  íŠ¹ì • ì‹ë‹¹ 1ê³³ì˜ íì—… í™•ë¥ ì„ ì˜ˆì¸¡í•˜ê³ (í”„ë¡œë°”) ë¡œì»¬ SHAPë¡œ ì£¼ìš” ìš”ì¸ Top-Nì„ ì„¤ëª…í•©ë‹ˆë‹¤.
- ì¡°ê±´ ì˜ˆ: í‰ì (stars) ë‚®ê³ , neighbor_density ë†’ê³ , stability_score ë‚®ì€ ë§¤ì¥ í•˜ë‚˜ ì„ ì •
- open ë§¤ì¥ë§Œ ëŒ€ìƒìœ¼ë¡œ í•„í„°ë§ + ì¹´í…Œê³ ë¦¬(ìƒŒë“œìœ„ì¹˜) í•„í„° ì¶”ê°€
- ê²°ê³¼:
  1) ì½˜ì†” ì¶œë ¥(í™•ë¥ /threshold/íŒì •/Top SHAP + %í¬ì¸íŠ¸ ì˜í–¥)
  2) CSV ì €ì¥: one_store_explain.csv (SHAP + í™•ë¥  ë³€í™” %p í¬í•¨)
"""

import pandas as pd
import numpy as np
from catboost import CatBoostClassifier, Pool
import shap

# =========
# 0. ì…ë ¥
# =========
DF_PATH = "df11.csv"
MODEL_PATH = "catboost_df11_close_real_bestF1.cbm"
BEST_THR = None   # ì˜ˆ: 0.23 (í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì¶œë ¥ëœ best_thrë¥¼ ë„£ìœ¼ë©´ ì¼ê´€ì„±â†‘)
TARGET_BUSINESS_ID = None  # ì˜ˆ: "abc123" (ì§ì ‘ ì§€ì • ì‹œ)

# ğŸ”½ ì¶”ê°€: ì¹´í…Œê³ ë¦¬ í•„í„° ì´ë¦„ (ì›í•« ì»¬ëŸ¼ ì ‘ë‘ì–´ c_)
CATEGORY_NAME = "american_new"   # df11ì— ë³´í†µ c_american_new ë¡œ ì¡´ì¬ (ë‹¤ë¥´ë©´ ìë™ ê°ì§€ ì‹œë„)

# =========
# 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬(í•™ìŠµê³¼ ë™ì¼)
# =========
df = pd.read_csv(DF_PATH)
assert "store_status" in df.columns, "df11ì— store_statusê°€ í•„ìš”í•©ë‹ˆë‹¤."

# í•™ìŠµ ì‹œ ì‚¬ìš©í–ˆë˜ bool/ë§¤í•‘ ì „ì²˜ë¦¬(ê°„ë‹¨í™”: ì´ë¯¸ df11 ì €ì¥ ì‹œ ë°˜ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)
bool_cols = [
    "a_outdoor_seating", "a_good_for_group", "a_good_for_kids",
    "a_has_tv", "a_happy_hour"
]
for c in bool_cols:
    if c in df.columns:
        df[c] = df[c].fillna(0).astype(int)

noise_mapping = {"quiet": 0, "average": 1, "loud": 2, "very_loud": 3}
if "a_noise_level" in df.columns:
    df["a_noise_level"] = df["a_noise_level"].map(noise_mapping)

if "a_alcohol" in df.columns and "c_nightlife" in df.columns:
    df["a_alcohol"] = np.where(
        df["a_alcohol"].isna(),
        np.where(df["c_nightlife"] == 1, "full_bar", "none"),
        df["a_alcohol"]
    )
if "a_ambience" in df.columns:
    df["a_ambience"] = df["a_ambience"].fillna("unknown")

# get_dummies (store_status í¬í•¨: íƒ€ê¹ƒ ë”ë¯¸ ìƒì„±ë˜ì§€ë§Œ Xì—ëŠ” ë¯¸ì‚¬ìš©)
df_dum = pd.get_dummies(
    df.copy(),
    columns=["store_status", "a_alcohol", "a_ambience"],
    prefix=["status", "alcohol", "ambience"],
)

TARGET_COL = "status_close_real"
if TARGET_COL not in df_dum.columns:
    raise ValueError("status_close_real ë”ë¯¸ê°€ ì—†ìŠµë‹ˆë‹¤. get_dummies ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# í•™ìŠµ ì‹œ ì œì™¸í–ˆë˜ ì»¬ëŸ¼ê³¼ ë™ì¼í•˜ê²Œ feature cols êµ¬ì„±
exclude_cols = [
    "business_id", "name", "address", "city", "attributes", "categories", "hours",
    "is_open", "latitude", "longitude", TARGET_COL,
    "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday",
    "review_count"
]
status_cols = [c for c in df_dum.columns if c.startswith("status_")]
exclude_cols += [c for c in status_cols if c not in exclude_cols]

feature_cols = [c for c in df_dum.columns if c not in exclude_cols]
X_all = df_dum[feature_cols].copy()

cat_cols = [c for c in ["state", "postal_code"] if c in X_all.columns]
for col in X_all.columns:
    if col in cat_cols:
        X_all[col] = X_all[col].astype(str).fillna("missing")
    else:
        X_all[col] = X_all[col].fillna(0)

cat_feature_indices = [X_all.columns.get_loc(c) for c in cat_cols]

# =========
# 2. íƒ€ê¹ƒ ë§¤ì¥ ì„ íƒ ë¡œì§ (ìƒŒë“œìœ„ì¹˜ ì¹´í…Œê³ ë¦¬ í•„í„° í¬í•¨)
# =========
# c_american_new ì»¬ëŸ¼ëª… ìë™ íƒì§€ (ì˜ˆ: c_american_new / c_american_newes ë“±)
cand_cat_cols = [c for c in df.columns if c.startswith("c_") and CATEGORY_NAME in c]
if len(cand_cat_cols) == 0:
    # american_new ê´€ë ¨ ì›í•«ì´ ì—†ìœ¼ë©´ ê²½ê³  ì—†ì´ ì „ì²´ì—ì„œ ì§„í–‰
    cat_col = None
else:
    # american_new í‚¤ì›Œë“œ í¬í•¨ ê°€ì¥ ì§§ì€ ì»¬ëŸ¼ëª… ì„ íƒ
    cat_col = sorted(cand_cat_cols, key=len)[0]

if TARGET_BUSINESS_ID is not None and "business_id" in df.columns:
    row = df.loc[df["business_id"] == TARGET_BUSINESS_ID]
    if row.empty:
        raise ValueError("í•´ë‹¹ business_idê°€ df11ì— ì—†ìŠµë‹ˆë‹¤.")
    idx = row.index[0]
else:
    # ì¡°ê±´: open ë§¤ì¥ + (ì¹´í…Œê³ ë¦¬=ìƒŒë“œìœ„ì¹˜) + ë³„ì  ë‚®ìŒ + ê²½ìŸ ë†’ìŒ + ì•ˆì • ë‚®ìŒ
    conds = []
    conds.append(df["is_open"] == 1)  # âœ… ì˜¤í”ˆ ë§¤ì¥ë§Œ
    conds.append(df["review_count"] > 100)

    # âœ… ì¹´í…Œê³ ë¦¬(ìƒŒë“œìœ„ì¹˜) í•„í„°
    if cat_col is not None:
        conds.append(df[cat_col] == 1)

    if "stars" in df.columns:
        stars_p30 = df["stars"].quantile(0.3)
        conds.append(df["stars"] <= stars_p30)
    if "neighbor_density" in df.columns:
        nd_p70 = df["neighbor_density"].quantile(0.7)
        conds.append(df["neighbor_density"] >= nd_p70)
    if "stability_score" in df.columns:
        stab_p30 = df["stability_score"].quantile(0.3)
        conds.append(df["stability_score"] <= stab_p30)

    if conds:
        mask = np.logical_and.reduce(conds)
        candidates = df[mask]
        if candidates.empty:
            # ì¡°ê±´ ì™„í™”: (ìƒŒë“œìœ„ì¹˜ ìœ ì§€) open ë§¤ì¥ ì¤‘ ì•ˆì •ì§€ìˆ˜ ë‚®ì€ 200ê°œì—ì„œ ìš°ì„  ì„ íƒ
            base = df[(df["is_open"] == 1)]
            if cat_col is not None:
                base = base[base[cat_col] == 1]
            if "stability_score" in base.columns and len(base) > 0:
                candidates = base.nsmallest(min(200, len(base)), "stability_score")
            else:
                candidates = base.sample(min(200, len(base)), random_state=42)
    else:
        base = df[(df["is_open"] == 1)]
        if cat_col is not None:
            base = base[base[cat_col] == 1]
        candidates = base.sample(min(200, len(base)), random_state=42)

    # í›„ë³´ ì¤‘ì—ì„œ â€œí˜„ì¬ ëª¨ë¸ ê¸°ì¤€ ì˜ˆì¸¡ ìœ„í—˜ í™•ë¥ â€ì´ ê°€ì¥ ë†’ì€ 1ê°œ ì„ íƒ
    model_tmp = CatBoostClassifier()
    model_tmp.load_model(MODEL_PATH)

    X_cand = X_all.loc[candidates.index]
    proba_cand = model_tmp.predict_proba(X_cand)[:, 1]
    idx = X_cand.index[np.argmax(proba_cand)]

# =========
# 3. ë¡œë”© & ê°œë³„ ì˜ˆì¸¡ + ë¡œì»¬ SHAP
# =========
model = CatBoostClassifier()
model.load_model(MODEL_PATH)

x_row = X_all.loc[[idx]].copy()
pool_row = Pool(x_row, cat_features=cat_feature_indices)

proba = float(model.predict_proba(pool_row)[:, 1][0])

# threshold ì„¤ì •
if BEST_THR is None:
    thr = 0.5  # í•™ìŠµì—ì„œ ì°¾ì€ best_thrë¥¼ ë„£ìœ¼ë©´ ì¼ê´€ì„±â†‘
else:
    thr = float(BEST_THR)

pred = int(proba >= thr)

# ---------- ë¡œì»¬ SHAP ê³„ì‚° ----------
# CatBoost ShapValues: shape = (n_samples, n_features + 1) ; ë§ˆì§€ë§‰ ì—´ì´ base value(logit bias)
shap_vals_full = model.get_feature_importance(type="ShapValues", data=pool_row)
base_logit = float(shap_vals_full[0, -1])  # bias term (log-odds ê¸°ì¤€)
shap_vals = shap_vals_full[:, :-1]         # ë§ˆì§€ë§‰ bias ì œê±°
contrib = pd.Series(shap_vals[0], index=x_row.columns).sort_values(ascending=False)

top_pos = contrib.head(8)      # íì—…â†‘ë¡œ ë°€ì–´ì˜¬ë¦° ìš”ì¸
top_neg = contrib.tail(8)      # íì—…â†“ë¡œ ëˆŒëŸ¬ì¤€ ìš”ì¸

# ---------- SHAP â†’ í™•ë¥  ë³€í™”(%í¬ì¸íŠ¸) ë³€í™˜ ----------
def sigmoid(z):
    return 1.0 / (1.0 + np.exp(-z))

base_prob = sigmoid(base_logit)

def shap_to_pct_point(s):
    new_prob = sigmoid(base_logit + s)
    return (new_prob - base_prob) * 100.0  # percentage points

impact_pct = contrib.apply(shap_to_pct_point)

# ì›ë³¸ ì‹ë‹¹ ë©”íƒ€
meta_cols = ["business_id", "name", "state", "city", "stars", "review_count",
             "stability_score", "loyalty_score", "reliability_score",
             "neighbor_density"]
meta_cols = [c for c in meta_cols if c in df.columns]
meta = df.loc[idx, meta_cols].to_dict()

# =========
# 4. ì¶œë ¥
# =========
print("\n==== [ê°œë³„ ì‹ë‹¹ íì—… ìœ„í—˜ ì˜ˆì¸¡] ====")
print(f"- ëŒ€ìƒ ì¸ë±ìŠ¤: {idx}")
for k, v in meta.items():
    print(f"  {k}: {v}")
print(f"- ì˜ˆì¸¡ íì—… í™•ë¥ : {proba:.4f}")
print(f"- íŒì •(thr={thr:.2f}): {'íì—…(1)' if pred==1 else 'ë¹„íì—…(0)'}")

print("\n[ë¡œì»¬ SHAP ìƒìœ„ ê¸°ì—¬ ìš”ì¸ (íì—…â†‘)]")
for k, v in top_pos.items():
    print(f"  {k:30s} {v:+.5f}  (impact ~ {shap_to_pct_point(v):+.2f}%p)")

print("\n[ë¡œì»¬ SHAP í•˜ìœ„ ê¸°ì—¬ ìš”ì¸ (íì—…â†“)]")
for k, v in top_neg.items():
    print(f"  {k:30s} {v:+.5f}  (impact ~ {shap_to_pct_point(v):+.2f}%p)")

# =========
# 5. CSV ì €ì¥ (SHAP + í™•ë¥  ë³€í™” %p í¬í•¨)
# =========
out = pd.DataFrame({
    "feature": contrib.index,
    "shap_value": contrib.values,
    "impact_pct_point": impact_pct.values
})
out.insert(0, "business_index", idx)
out.insert(1, "pred_proba", proba)
out.insert(2, "pred_label", pred)
out.insert(3, "base_logit", base_logit)
out.insert(4, "base_prob", base_prob)

for k, v in meta.items():
    out[k] = v

out.to_csv("one_store_explain.csv", index=False, encoding="utf-8-sig")
print("\nâœ… ì €ì¥ ì™„ë£Œ: one_store_explain.csv")

# (ì„ íƒ) ìƒìœ„ 10ê°œ ì˜í–¥ë„ í‘œ ê°„ë‹¨ ì¶œë ¥
print("\n[í™•ë¥  ë³€í™” ê¸°ì¤€ Top 10 ìš”ì¸ (%p)]")
tmp = out[["feature","impact_pct_point"]].copy().sort_values("impact_pct_point", ascending=False).head(10)
for _, r in tmp.iterrows():
    print(f"  {r['feature']:30s} {r['impact_pct_point']:+.2f}%p")
